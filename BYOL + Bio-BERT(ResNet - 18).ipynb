{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eacba668-e454-45e5-a4f5-0263bc9f6e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213357 images have loaded for training\n",
      "4774 images have loaded for validation\n",
      "4774 images have loaded for testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "  0%|                                                                                                                           | 0/3333 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 168\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected batch structure: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 168\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m    169\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    171\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "from data import DataLoader as CustomDataLoader\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='training.log', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load configuration\n",
    "config_file = \"config1.yaml\"\n",
    "with open(config_file, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "config['data_pct'] = 100\n",
    "\n",
    "# Data loading\n",
    "data_ins = CustomDataLoader(config)\n",
    "train_loader, valid_loader, test_loader = data_ins.GetMimicDataset()\n",
    "\n",
    "# Define the ResNet18-based model with BYOL\n",
    "class BYOL(nn.Module):\n",
    "    def __init__(self, base_encoder, hidden_dim=4096, projection_dim=256, num_classes=15, moving_average_decay=0.99):\n",
    "        super(BYOL, self).__init__()\n",
    "        self.base_encoder = base_encoder\n",
    "        self.projection_dim = projection_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Determine the output size from base_encoder\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 3, 224, 224).to(device)\n",
    "            output_size = self.base_encoder(dummy_input).view(1, -1).size(1)\n",
    "\n",
    "        self.online_encoder = nn.Sequential(\n",
    "            self.base_encoder,\n",
    "            nn.Linear(output_size, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, projection_dim)\n",
    "        )\n",
    "\n",
    "        self.target_encoder = nn.Sequential(\n",
    "            self.base_encoder,\n",
    "            nn.Linear(output_size, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, projection_dim)\n",
    "        )\n",
    "\n",
    "        for param_online, param_target in zip(self.online_encoder.parameters(), self.target_encoder.parameters()):\n",
    "            param_target.data.copy_(param_online.data)\n",
    "            param_target.requires_grad = False\n",
    "\n",
    "        self.moving_average_decay = moving_average_decay\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(output_size, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2=None):\n",
    "        if x2 is None:\n",
    "            return self.classifier(self.base_encoder(x1))\n",
    "\n",
    "        online_proj_one = self.online_encoder(x1)\n",
    "        online_proj_two = self.online_encoder(x2)\n",
    "        target_proj_one = self.target_encoder(x1).detach()\n",
    "        target_proj_two = self.target_encoder(x2).detach()\n",
    "        return online_proj_one, online_proj_two, target_proj_one, target_proj_two\n",
    "\n",
    "    def update_target_network(self):\n",
    "        for param_online, param_target in zip(self.online_encoder.parameters(), self.target_encoder.parameters()):\n",
    "            param_target.data = self.moving_average_decay * param_target.data + (1 - self.moving_average_decay) * param_online.data\n",
    "\n",
    "# Define the BYOL loss function\n",
    "def byol_loss(p1, p2, z1, z2):\n",
    "    loss_one = 2 - 2 * (p1 * z2.detach()).sum(dim=-1)\n",
    "    loss_two = 2 - 2 * (p2 * z1.detach()).sum(dim=-1)\n",
    "    return (loss_one + loss_two).mean()\n",
    "\n",
    "# Define transformations for BYOL\n",
    "byol_transforms = T.Compose([\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.5),\n",
    "    T.RandomRotation(30),\n",
    "    T.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Model initialization\n",
    "num_classes = 15\n",
    "base_encoder = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1).to(device)\n",
    "byol_model = BYOL(base_encoder, hidden_dim=4096, projection_dim=256, num_classes=num_classes).to(device)\n",
    "\n",
    "# Initialize BioBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "biobert_model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\").to(device)\n",
    "\n",
    "# Define combined model\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, image_model, text_model, image_feature_dim, text_feature_dim, hidden_dim=512, num_classes=15):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.image_model = image_model\n",
    "        self.text_model = text_model\n",
    "        self.fc_image = nn.Linear(image_feature_dim, hidden_dim)\n",
    "        self.fc_text = nn.Linear(text_feature_dim, hidden_dim)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        image_features = self.image_model(images)\n",
    "        text_outputs = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = text_outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        combined_features = F.relu(self.fc_image(image_features)) + F.relu(self.fc_text(text_features))\n",
    "        output = torch.sigmoid(self.classifier(combined_features))\n",
    "        return output\n",
    "\n",
    "# Instantiate combined model\n",
    "image_feature_dim = 4096  # Change based on your BYOL output dimension\n",
    "text_feature_dim = 768  # BioBERT output dimension\n",
    "combined_model = CombinedModel(byol_model, biobert_model, image_feature_dim, text_feature_dim).to(device)\n",
    "\n",
    "# Training and validation setup\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(combined_model.parameters(), lr=learning_rate)\n",
    "classification_criterion = nn.BCELoss()\n",
    "\n",
    "# Training loop for the combined model\n",
    "total_start_time = time.time()\n",
    "roc_auc_scores = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    combined_model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        if len(batch) == 3:\n",
    "            images, text, labels = batch\n",
    "            input_ids = text['input_ids']\n",
    "            attention_mask = text['attention_mask']\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "        elif len(batch) == 2:\n",
    "            images, labels = batch\n",
    "            input_ids = None\n",
    "            attention_mask = None\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected batch structure: {len(batch)} elements\")\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = combined_model(images, input_ids, attention_mask)\n",
    "        loss = classification_criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    logging.info(f\"Epoch [{epoch+1}/{num_epochs}], Classification Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    combined_model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader):\n",
    "            if len(batch) == 3:\n",
    "                images, text, labels = batch\n",
    "                input_ids = text['input_ids']\n",
    "                attention_mask = text['attention_mask']\n",
    "                input_ids = input_ids.to(device)\n",
    "                attention_mask = attention_mask.to(device)\n",
    "            elif len(batch) == 2:\n",
    "                images, labels = batch\n",
    "                input_ids = None\n",
    "                attention_mask = None\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected batch structure: {len(batch)} elements\")\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = combined_model(images, input_ids, attention_mask)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    roc_auc = roc_auc_score(all_labels, all_preds, average=None)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "\n",
    "    logging.info(f\"Epoch [{epoch+1}/{num_epochs}], Validation ROC AUC: {roc_auc}\")\n",
    "\n",
    "total_end_time = time.time()\n",
    "total_duration = total_end_time - total_start_time\n",
    "logging.info(f\"Total Training Time: {total_duration:.2f} seconds\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(combined_model.state_dict(), \"combined_model.pth\")\n",
    "\n",
    "# Plot ROC AUC scores\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(num_classes):\n",
    "    plt.plot([roc_auc[i] for roc_auc in roc_auc_scores], label=f'Class {i}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.title('ROC AUC Scores per Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aee004-2bc7-4c8d-8143-22fed5e91f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
