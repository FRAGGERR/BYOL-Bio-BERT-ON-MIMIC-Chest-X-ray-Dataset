{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b64d5d-53c5-4f1f-a424-277ece49e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "from optimizer import LARS\n",
    "from utils import log, AverageMeter, collect_params\n",
    "\n",
    "# from data import DataLoader as CustomDataLoader\n",
    "from data import DataLoader\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83d95b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from byol import BYOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ecb1274-ac35-4ed5-84a0-a5e65d979e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data loading\n",
    "# data_ins   = DataLoader(config)\n",
    "# # train_loader, valid_loader, test_loader = data_ins.GetMimicDataset() #you are not supposed to use the mimic dataset\n",
    "# #you need to use the multimodal data\n",
    "# train_loader, valid_loader = data_ins.GetMultimodalPretrainingDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "440ce400-7386-401a-9698-ae85f484f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define custom BYOL model\n",
    "# class ProjectionHead(nn.Module):\n",
    "#     def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "#         super(ProjectionHead, self).__init__()\n",
    "#         self.block = nn.Sequential(\n",
    "#             nn.Linear(in_dim, hidden_dim),\n",
    "#             nn.BatchNorm1d(hidden_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_dim, out_dim)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.block(x)\n",
    "\n",
    "# class PredictionHead(nn.Module):\n",
    "#     def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "#         super(PredictionHead, self).__init__()\n",
    "#         self.block = nn.Sequential(\n",
    "#             nn.Linear(in_dim, hidden_dim),\n",
    "#             nn.BatchNorm1d(hidden_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_dim, out_dim)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.block(x)\n",
    "\n",
    "# class BYOL(nn.Module):\n",
    "#     def __init__(self, backbone):\n",
    "#         super(BYOL, self).__init__()\n",
    "#         self.backbone = backbone\n",
    "#         self.projection_head = ProjectionHead(2048, 4096, 256)\n",
    "#         self.prediction_head = PredictionHead(256, 4096, 256)\n",
    "\n",
    "#         self.backbone_momentum = copy.deepcopy(self.backbone)\n",
    "#         self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
    "\n",
    "#         for param in self.backbone_momentum.parameters():\n",
    "#             param.requires_grad = False\n",
    "#         for param in self.projection_head_momentum.parameters():\n",
    "#             param.requires_grad = False\n",
    "\n",
    "#     def forward_online(self, x):\n",
    "#         y = self.backbone(x).flatten(start_dim=1)\n",
    "#         z = self.projection_head(y)\n",
    "#         p = self.prediction_head(z)\n",
    "#         return p\n",
    "\n",
    "# #     def forward_momentum(self, x):\n",
    "#     def forward_target(self, x):\n",
    "#         y = self.backbone_momentum(x).flatten(start_dim=1)\n",
    "#         z = self.projection_head_momentum(y)\n",
    "#         z = z.detach()\n",
    "#         return z\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         online = self.forward_online(x)\n",
    "#         target = self.forward_target(x)\n",
    "        \n",
    "#         return online, target\n",
    "    \n",
    "\n",
    "# def negative_cosine_similarity(p, z):\n",
    "#     return -F.cosine_similarity(p, z.detach(), dim=-1).mean()\n",
    "\n",
    "# def vicreg_loss(x, y, sim_weight=25.0, var_weight=25.0, cov_weight=1.0):\n",
    "# #     repr_loss = F.mse_loss(x, y)\n",
    "\n",
    "#     x = x - x.mean(dim=0)\n",
    "#     y = y - y.mean(dim=0)\n",
    "    \n",
    "#     std_x = torch.sqrt(x.var(dim=0) + 1e-4)\n",
    "#     std_y = torch.sqrt(y.var(dim=0) + 1e-4)\n",
    "#     std_loss = (torch.mean(F.relu(1 - std_x)) + torch.mean(F.relu(1 - std_y))) * var_weight\n",
    "    \n",
    "#     cov_x = (x.T @ x) / (x.size(0) - 1)\n",
    "#     cov_y = (y.T @ y) / (y.size(0) - 1)\n",
    "#     cov_loss = (off_diagonal(cov_x).pow_(2).sum() + off_diagonal(cov_y).pow_(2).sum()) * cov_weight\n",
    "    \n",
    "#     return std_loss + cov_loss\n",
    "\n",
    "# def off_diagonal(x):\n",
    "#     n, m = x.shape\n",
    "#     assert n == m\n",
    "#     return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ce24bb-4037-495c-a2ec-e73aa45edd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BYOL\n",
    "# resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1).to(device)\n",
    "# backbone = nn.Sequential(*list(resnet.children())[:-1]).to(device) ##added .to(device)\n",
    "# byol_model = BYOL(backbone).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a2d377-7c14-4210-90c3-b772378726f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TextProjectionHead(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         embedding_dim= 768\n",
    "#         projection_dim=256\n",
    "#         dropout=0.2\n",
    "        \n",
    "#         self.projection = nn.Linear(embedding_dim, projection_dim)\n",
    "#         self.gelu       = nn.GELU()\n",
    "#         self.fc         = nn.Linear(projection_dim, projection_dim)\n",
    "#         self.dropout    = nn.Dropout(dropout)\n",
    "#         self.layer_norm = nn.LayerNorm(projection_dim)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         projected = self.projection(x)\n",
    "#         x = self.gelu(projected)\n",
    "#         x = self.fc(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = x + projected\n",
    "#         x = self.layer_norm(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "683649fe-95ef-41e3-932b-cc2c79779199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self ):\n",
    "        super().__init__()\n",
    "\n",
    "        model_name=\"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "        pretrained=True\n",
    "        trainable=False\n",
    "        \n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(model_name)\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = trainable\n",
    "\n",
    "        # we are using the CLS token hidden representation as the sentence's embedding\n",
    "        self.target_token_idx = 0\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.model(input_ids=input_ids, attention_mask=attention_mask,return_dict=False)\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "519c998f-f7ac-4079-a137-635fda76f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CombinedModel(nn.Module):\n",
    "#     def __init__(self, image_model, text_model):\n",
    "#         super(CombinedModel, self).__init__()\n",
    "#         self.image_model = image_model\n",
    "#         self.text_model = text_model\n",
    "#         # self.fc = nn.Linear(256, 1)##changed\n",
    "    \n",
    "#     def forward(self, images, input_ids, attention_mask):\n",
    "#         online, target = self.image_model(images)\n",
    "#         text_features = self.text_model(input_ids,attention_mask)\n",
    "#         # outputs = self.fc(text_features) ##changed\n",
    "#         return online, target, text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83d0a91d-12ab-4fbd-9c6e-72ef82bb3872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# biobert_model = TextEncoder()\n",
    "# combined_model = CombinedModel(byol_model, biobert_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01dd7706-ddb8-4efd-920e-b8e25e61b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training and validation\n",
    "# num_epochs = 10\n",
    "# learning_rate = 0.001\n",
    "# optimizer = torch.optim.Adam(combined_model.parameters(), lr=learning_rate)\n",
    "# classification_criterion = nn.BCELoss()\n",
    "\n",
    "# # Training loop for the combined model\n",
    "# total_start_time = time.time()\n",
    "# roc_auc_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bffbef5e-52e6-438e-adbe-1b78f66df545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# Initialize logging\n",
    "# logging.basicConfig(filename='training.log', level=logging.INFO, \n",
    "#                     format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Device configuration\n",
    "# device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e27a066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for the combined model\n",
    "# num_epochs = 300\n",
    "class Trainer():\n",
    "    def __init__(self,config):\n",
    "        self.config = config\n",
    "        self.total_epochs  = config['optimizer']['total_epochs']\n",
    "        self.warmup_epochs = config['optimizer']['warmup_epochs']\n",
    "        self.batch_size = config['pre_bs']\n",
    "        \n",
    "        self.data_ins = DataLoader(config)\n",
    "        self.train_loader, self.valid_loader = self.data_ins.GetMultimodalPretrainingDataset()        \n",
    "        \n",
    "        num_examples = len(self.train_loader)*self.batch_size\n",
    "        self.warmup_steps  = self.warmup_epochs * num_examples//self.batch_size    \n",
    "        self.total_steps   = self.total_epochs * num_examples //self.batch_size\n",
    "\n",
    "        self.base_lr   = self.config['optimizer']['base_lr']/256\n",
    "        self.max_lr    = self.base_lr * self.batch_size\n",
    "        \n",
    "        self.base_mm   = self.config['model']['base_momentum']\n",
    "        self.gpu       = self.config['gpu']\n",
    "        \n",
    "        self.resume_path = self.config['checkpoint']['resume_path']\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(f'cuda:{self.gpu}')\n",
    "            torch.cuda.set_device(self.device)\n",
    "            cudnn.benchmark = True\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "        self.model_name = self.config['model']['model_name']\n",
    "        self.dataset = self.config['dataset']\n",
    "        \n",
    "        save_path   = os.path.join('./ckpt',self.model_name.lower())\n",
    "        self.method_name = f\"{config['model']['backbone']['type']}_{self.dataset}_{self.batch_size}_{self.total_epochs}\"\n",
    "        self.config['checkpoint']['ckpt_path'] = os.path.join(save_path,self.method_name)        \n",
    "        os.makedirs(config['checkpoint']['ckpt_path'], exist_ok=True)\n",
    "        self.logger = log(path=config['checkpoint']['ckpt_path'], file=f\"{self.method_name}.logs\")\n",
    "        \n",
    "        \"\"\"log tools in the running phase\"\"\"\n",
    "        self.steps = 0\n",
    "        self.total_training_time = 0\n",
    "        self.log_step   = self.config['checkpoint']['log_step']\n",
    "        self.save_epoch = self.config['checkpoint']['save_epoch']\n",
    "        self.construct_model()\n",
    "        \n",
    "    def construct_model(self):\n",
    "        self.logger.info(\"init model!\")\n",
    "                \n",
    "        byol_model = BYOL(self.config)\n",
    "        self.image_model = byol_model.to(self.device)\n",
    "        self.logger.info(self.image_model)\n",
    "        \n",
    "        self.text_encoder     = TextEncoder().to(self.device)\n",
    "#         self.text_projection  = TextProjectionHead().to(self.device)        \n",
    "        self.logger.info(self.text_encoder)\n",
    "#         self.logger.info(self.text_projection)\n",
    "\n",
    "\n",
    "        self.logger.info(\"get optimizer!\")\n",
    "        momentum = self.config['optimizer']['momentum']\n",
    "        weight_decay = self.config['optimizer']['weight_decay']\n",
    "        exclude_bias_and_bn = self.config['optimizer']['exclude_bias_and_bn']\n",
    "        params = collect_params([self.image_model.online_network, self.image_model.predictor],exclude_bias_and_bn=exclude_bias_and_bn)\n",
    "        self.optimizer = LARS(params, lr=self.max_lr,momentum=momentum, weight_decay=weight_decay)\n",
    "        \n",
    "    def resume_model(self, model_path=None):\n",
    "        if model_path is None and not self.resume_path:\n",
    "            self.start_epoch = 0\n",
    "            self.logger.info(\"--> No loaded checkpoint!\")\n",
    "        else:\n",
    "            model_path = model_path or self.resume_path\n",
    "            checkpoint = torch.load(model_path, map_location=self.device)\n",
    "\n",
    "            self.start_epoch = checkpoint['epoch']\n",
    "            self.steps = checkpoint['steps']\n",
    "            self.model.load_state_dict(checkpoint['model'], strict=True)\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            self.logger.info(f\"--> Loaded checkpoint '{model_path}' (epoch {self.start_epoch})\")\n",
    "\n",
    "    # save snapshots\n",
    "    def save_checkpoint(self, epoch):\n",
    "        if epoch % self.save_epoch == 0:\n",
    "            model_state = {'config': self.config,\n",
    "                           'epoch': epoch,\n",
    "                           'steps': self.steps,\n",
    "                           'model': self.image_model.state_dict(),\n",
    "                           'online': self.image_model.online_network.state_dict(),\n",
    "                           'optimizer': self.optimizer.state_dict(),\n",
    "                     }\n",
    "            online_state = {'online': self.image_model.online_network.state_dict()}\n",
    "            SAVE_PATH1 = os.path.join(self.config['checkpoint']['ckpt_path'], f'{self.method_name}.pth')\n",
    "            SAVE_PATH2 = os.path.join(self.config['checkpoint']['ckpt_path'], f'{self.method_name}_{epoch}.pth')\n",
    "            torch.save(model_state, SAVE_PATH1)\n",
    "            torch.save(online_state, SAVE_PATH2)\n",
    "            \n",
    "    def adjust_learning_rate(self, step):\n",
    "        \"\"\"learning rate warm up and decay\"\"\"\n",
    "        max_lr = self.max_lr\n",
    "        min_lr = 1e-3 * self.max_lr\n",
    "        if step < self.warmup_steps:\n",
    "            lr = (max_lr - min_lr) * step / self.warmup_steps + min_lr\n",
    "        else:\n",
    "            lr = min_lr + 0.5 * \\\n",
    "                (max_lr - min_lr) * (1 + np.cos((step - self.warmup_steps) * np.pi / self.total_steps))\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def adjust_mm(self, step):\n",
    "        self.mm = 1 - (1 - self.base_mm) * \\\n",
    "            (np.cos(np.pi * step / self.total_steps) + 1) / 2\n",
    "    \n",
    "    def regression_loss(self, preds, targets):\n",
    "        bz = preds.size(0)\n",
    "        preds_norm = F.normalize(preds, dim=1)\n",
    "        targets_norm = F.normalize(targets, dim=1)\n",
    "        loss = 2 - 2 * (preds_norm * targets_norm).sum() / bz\n",
    "        return loss\n",
    "    \n",
    "#     def compute_variance(self,x):\n",
    "#         x = x - x.mean(dim=0)\n",
    "# #         y = y - y.mean(dim=0)\n",
    "\n",
    "#         std_x = torch.sqrt(x.var(dim=0) + 1e-4)\n",
    "# #         std_y = torch.sqrt(y.var(dim=0) + 1e-4)\n",
    "# #         std_loss = (torch.mean(F.relu(1 - std_x)) + torch.mean(F.relu(1 - std_y))) * var_weight\n",
    "#         return std_x \n",
    "\n",
    "    \n",
    "    def recursive_to_device(self, inp, device):\n",
    "        if isinstance(inp, list):\n",
    "            return [self.recursive_to_device(item, device) for item in inp]\n",
    "        elif isinstance(inp, torch.Tensor):\n",
    "            return inp.to(device)\n",
    "        else:\n",
    "            return inp\n",
    "        \n",
    "    def train_epoch(self, epoch):\n",
    "        loss_meter    = AverageMeter()\n",
    "        var_loss_meter  = AverageMeter()\n",
    "        loss_byol_meter = AverageMeter()\n",
    "            \n",
    "        self.image_model.train()\n",
    "#         self.text_projection.train()\n",
    "        \n",
    "        epoch_start_time = time.time() \n",
    "        \n",
    "        for idx, batch in enumerate(self.train_loader):\n",
    "            input_ids = batch['caption_ids'].to(self.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.device)\n",
    "            imgs = batch['imgs']\n",
    "            imgs = self.recursive_to_device(imgs, self.device)\n",
    "\n",
    "            self.adjust_mm(self.steps)\n",
    "            self.adjust_learning_rate(self.steps)\n",
    "            self.steps += 1\n",
    "            \n",
    "            q1,q2, target_z1,target_z2 = self.image_model(imgs, self.mm)\n",
    "            \n",
    "            text_features   = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             text_embeddings = self.text_projection(text_features)\n",
    "            \n",
    "            loss_byol = self.regression_loss(q1,target_z2)\n",
    "            loss_byol += self.regression_loss(q2,target_z1)\n",
    "            \n",
    "            variance_I = torch.var(q1, dim=0)\n",
    "            variance_I += torch.var(q2, dim=0)\n",
    "            \n",
    "            variance_T = torch.var(text_features, dim=0)            \n",
    "            var_loss = F.mse_loss(variance_I, variance_T)\n",
    "            \n",
    "            loss = loss_byol + 10*var_loss\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            loss_meter.update(loss.item(), imgs[0].size(0))\n",
    "            var_loss_meter.update(var_loss.item(), imgs[0].size(0))\n",
    "            loss_byol_meter.update(loss_byol.item(), imgs[0].size(0))\n",
    "\n",
    "            # Print log info\n",
    "            if self.steps % self.log_step == 0:\n",
    "                lr = self.optimizer.param_groups[0][\"lr\"]\n",
    "                mm = self.mm\n",
    "                self.logger.info(f'Epoch: [{epoch}][{idx}/{len(self.train_loader)}]\\t'\n",
    "                                f'Step {self.steps}\\t'\n",
    "                                f'lr {round(self.optimizer.param_groups[0][\"lr\"], 5)}\\t'\n",
    "                                f'mm {round(self.mm, 5)}\\t'\n",
    "                                f'Loss {loss_meter.val:.4f} \\t'\n",
    "                                f'B_Loss {loss_byol_meter.val:.4f} \\t'\n",
    "                                f'V_Loss {var_loss_meter.val:.4f} \\t'\n",
    "                                )\n",
    "                \n",
    "        epoch_end_time = time.time()  # End time of current epoch\n",
    "        epoch_training_time = (epoch_end_time - epoch_start_time)/60\n",
    "        self.total_training_time += epoch_training_time\n",
    "        self.logger.info(f\"Epoch {epoch} training time: {epoch_training_time:.2f} minutes\")\n",
    "        if epoch == self.total_epochs +1:\n",
    "            self.total_training_time_hours = self.total_training_time / 3600  \n",
    "            self.logger.info(f\"Total training time: {self.total_training_time_hours:.2f} hours\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec2004c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task(config):\n",
    "    trainer = Trainer(config)\n",
    "    trainer.resume_model(model_path=None)\n",
    "    start_epoch = trainer.start_epoch\n",
    "    for epoch in range(start_epoch + 1, trainer.total_epochs + 1):\n",
    "        trainer.train_epoch(epoch)\n",
    "        trainer.save_checkpoint(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e0ce86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:init model!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227327 images have loaded for training\n",
      "4959 images have loaded for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "INFO:root:BYOL(\n",
      "  (online_network): EncoderwithProjection(\n",
      "    (encoder): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    )\n",
      "    (projetion): MLP(\n",
      "      (l1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      (bn1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (l2): Linear(in_features=4096, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (target_network): EncoderwithProjection(\n",
      "    (encoder): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    )\n",
      "    (projetion): MLP(\n",
      "      (l1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      (bn1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (l2): Linear(in_features=4096, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (predictor): Predictor_MLP(\n",
      "    (predictor): MLP(\n",
      "      (l1): Linear(in_features=768, out_features=4096, bias=True)\n",
      "      (bn1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (l2): Linear(in_features=4096, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "INFO:root:TextEncoder(\n",
      "  (model): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:get optimizer!\n",
      "INFO:root:--> No loaded checkpoint!\n",
      "INFO:root:Epoch: [1][49/3551]\tStep 50\tlr 1e-05\tmm 0.996\tLoss 4.4693 \tB_Loss 3.9897 \tV_Loss 0.0480 \t\n",
      "INFO:root:Epoch: [1][99/3551]\tStep 100\tlr 2e-05\tmm 0.996\tLoss 4.4754 \tB_Loss 3.9847 \tV_Loss 0.0491 \t\n",
      "INFO:root:Epoch: [1][149/3551]\tStep 150\tlr 3e-05\tmm 0.996\tLoss 4.4607 \tB_Loss 3.9877 \tV_Loss 0.0473 \t\n",
      "INFO:root:Epoch: [1][199/3551]\tStep 200\tlr 3e-05\tmm 0.996\tLoss 4.4184 \tB_Loss 3.9629 \tV_Loss 0.0455 \t\n",
      "INFO:root:Epoch: [1][249/3551]\tStep 250\tlr 4e-05\tmm 0.996\tLoss 4.3931 \tB_Loss 3.9424 \tV_Loss 0.0451 \t\n",
      "INFO:root:Epoch: [1][299/3551]\tStep 300\tlr 5e-05\tmm 0.996\tLoss 4.3529 \tB_Loss 3.8961 \tV_Loss 0.0457 \t\n",
      "INFO:root:Epoch: [1][349/3551]\tStep 350\tlr 5e-05\tmm 0.996\tLoss 4.3279 \tB_Loss 3.8616 \tV_Loss 0.0466 \t\n",
      "INFO:root:Epoch: [1][399/3551]\tStep 400\tlr 6e-05\tmm 0.996\tLoss 4.2749 \tB_Loss 3.8076 \tV_Loss 0.0467 \t\n",
      "INFO:root:Epoch: [1][449/3551]\tStep 450\tlr 7e-05\tmm 0.996\tLoss 4.2013 \tB_Loss 3.7675 \tV_Loss 0.0434 \t\n",
      "INFO:root:Epoch: [1][499/3551]\tStep 500\tlr 8e-05\tmm 0.996\tLoss 4.1725 \tB_Loss 3.7233 \tV_Loss 0.0449 \t\n",
      "INFO:root:Epoch: [1][549/3551]\tStep 550\tlr 8e-05\tmm 0.996\tLoss 4.0659 \tB_Loss 3.6322 \tV_Loss 0.0434 \t\n",
      "INFO:root:Epoch: [1][699/3551]\tStep 700\tlr 0.0001\tmm 0.996\tLoss 3.7470 \tB_Loss 3.3483 \tV_Loss 0.0399 \t\n",
      "INFO:root:Epoch: [1][749/3551]\tStep 750\tlr 0.00011\tmm 0.996\tLoss 3.6045 \tB_Loss 3.2361 \tV_Loss 0.0368 \t\n",
      "INFO:root:Epoch: [1][799/3551]\tStep 800\tlr 0.00012\tmm 0.996\tLoss 3.5120 \tB_Loss 3.1294 \tV_Loss 0.0383 \t\n",
      "INFO:root:Epoch: [1][849/3551]\tStep 850\tlr 0.00012\tmm 0.996\tLoss 3.3523 \tB_Loss 3.0030 \tV_Loss 0.0349 \t\n",
      "INFO:root:Epoch: [1][899/3551]\tStep 900\tlr 0.00013\tmm 0.996\tLoss 3.2057 \tB_Loss 2.8658 \tV_Loss 0.0340 \t\n",
      "INFO:root:Epoch: [1][949/3551]\tStep 950\tlr 0.00014\tmm 0.996\tLoss 3.0836 \tB_Loss 2.7565 \tV_Loss 0.0327 \t\n",
      "INFO:root:Epoch: [1][999/3551]\tStep 1000\tlr 0.00015\tmm 0.996\tLoss 2.9564 \tB_Loss 2.6495 \tV_Loss 0.0307 \t\n",
      "INFO:root:Epoch: [1][1049/3551]\tStep 1050\tlr 0.00015\tmm 0.996\tLoss 2.7802 \tB_Loss 2.5310 \tV_Loss 0.0249 \t\n",
      "INFO:root:Epoch: [1][1099/3551]\tStep 1100\tlr 0.00016\tmm 0.996\tLoss 2.6914 \tB_Loss 2.4319 \tV_Loss 0.0259 \t\n",
      "INFO:root:Epoch: [1][1199/3551]\tStep 1200\tlr 0.00017\tmm 0.996\tLoss 2.4377 \tB_Loss 2.2408 \tV_Loss 0.0197 \t\n",
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n",
      "INFO:root:Epoch: [1][1249/3551]\tStep 1250\tlr 0.00018\tmm 0.996\tLoss 2.3382 \tB_Loss 2.1788 \tV_Loss 0.0159 \t\n",
      "INFO:root:Epoch: [1][1299/3551]\tStep 1300\tlr 0.00019\tmm 0.996\tLoss 2.2492 \tB_Loss 2.0961 \tV_Loss 0.0153 \t\n",
      "INFO:root:Epoch: [1][1349/3551]\tStep 1350\tlr 0.00019\tmm 0.996\tLoss 2.1942 \tB_Loss 2.0665 \tV_Loss 0.0128 \t\n",
      "INFO:root:Epoch: [1][1399/3551]\tStep 1400\tlr 0.0002\tmm 0.996\tLoss 2.1481 \tB_Loss 2.0567 \tV_Loss 0.0091 \t\n",
      "INFO:root:Epoch: [1][1449/3551]\tStep 1450\tlr 0.00021\tmm 0.996\tLoss 2.0745 \tB_Loss 2.0039 \tV_Loss 0.0071 \t\n",
      "INFO:root:Epoch: [1][1499/3551]\tStep 1500\tlr 0.00022\tmm 0.996\tLoss 2.0704 \tB_Loss 1.9951 \tV_Loss 0.0075 \t\n",
      "INFO:root:Epoch: [1][1549/3551]\tStep 1550\tlr 0.00022\tmm 0.996\tLoss 2.0289 \tB_Loss 1.9790 \tV_Loss 0.0050 \t\n",
      "INFO:root:Epoch: [1][1599/3551]\tStep 1600\tlr 0.00023\tmm 0.996\tLoss 2.0078 \tB_Loss 1.9688 \tV_Loss 0.0039 \t\n",
      "INFO:root:Epoch: [1][1649/3551]\tStep 1650\tlr 0.00024\tmm 0.996\tLoss 2.0025 \tB_Loss 1.9729 \tV_Loss 0.0030 \t\n",
      "INFO:root:Epoch: [1][1699/3551]\tStep 1700\tlr 0.00024\tmm 0.996\tLoss 1.9945 \tB_Loss 1.9694 \tV_Loss 0.0025 \t\n",
      "INFO:root:Epoch: [1][1749/3551]\tStep 1750\tlr 0.00025\tmm 0.996\tLoss 1.9875 \tB_Loss 1.9630 \tV_Loss 0.0025 \t\n",
      "INFO:root:Epoch: [1][1799/3551]\tStep 1800\tlr 0.00026\tmm 0.996\tLoss 2.0477 \tB_Loss 2.0213 \tV_Loss 0.0026 \t\n",
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n",
      "INFO:root:Epoch: [1][1849/3551]\tStep 1850\tlr 0.00027\tmm 0.996\tLoss 1.9562 \tB_Loss 1.9341 \tV_Loss 0.0022 \t\n",
      "INFO:root:Epoch: [1][1899/3551]\tStep 1900\tlr 0.00027\tmm 0.996\tLoss 1.9488 \tB_Loss 1.9277 \tV_Loss 0.0021 \t\n",
      "INFO:root:Epoch: [1][1949/3551]\tStep 1950\tlr 0.00028\tmm 0.996\tLoss 1.9694 \tB_Loss 1.9441 \tV_Loss 0.0025 \t\n",
      "INFO:root:Epoch: [1][1999/3551]\tStep 2000\tlr 0.00029\tmm 0.996\tLoss 1.9969 \tB_Loss 1.9748 \tV_Loss 0.0022 \t\n",
      "INFO:root:Epoch: [1][2049/3551]\tStep 2050\tlr 0.00029\tmm 0.996\tLoss 1.9436 \tB_Loss 1.9112 \tV_Loss 0.0032 \t\n",
      "INFO:root:Epoch: [1][2099/3551]\tStep 2100\tlr 0.0003\tmm 0.996\tLoss 1.9554 \tB_Loss 1.9169 \tV_Loss 0.0038 \t\n",
      "INFO:root:Epoch: [1][2149/3551]\tStep 2150\tlr 0.00031\tmm 0.996\tLoss 1.8638 \tB_Loss 1.8226 \tV_Loss 0.0041 \t\n",
      "INFO:root:Epoch: [1][2199/3551]\tStep 2200\tlr 0.00031\tmm 0.996\tLoss 1.8572 \tB_Loss 1.8108 \tV_Loss 0.0046 \t\n",
      "INFO:root:Epoch: [1][2249/3551]\tStep 2250\tlr 0.00032\tmm 0.996\tLoss 1.9137 \tB_Loss 1.8718 \tV_Loss 0.0042 \t\n",
      "INFO:root:Epoch: [1][2299/3551]\tStep 2300\tlr 0.00033\tmm 0.996\tLoss 1.7113 \tB_Loss 1.6396 \tV_Loss 0.0072 \t\n",
      "INFO:root:Epoch: [1][2349/3551]\tStep 2350\tlr 0.00034\tmm 0.996\tLoss 1.7273 \tB_Loss 1.6717 \tV_Loss 0.0056 \t\n",
      "INFO:root:Epoch: [1][2399/3551]\tStep 2400\tlr 0.00034\tmm 0.996\tLoss 1.7070 \tB_Loss 1.6488 \tV_Loss 0.0058 \t\n",
      "INFO:root:Epoch: [1][2449/3551]\tStep 2450\tlr 0.00035\tmm 0.996\tLoss 1.7007 \tB_Loss 1.6276 \tV_Loss 0.0073 \t\n",
      "INFO:root:Epoch: [1][2499/3551]\tStep 2500\tlr 0.00036\tmm 0.996\tLoss 1.7138 \tB_Loss 1.6548 \tV_Loss 0.0059 \t\n",
      "INFO:root:Epoch: [1][2549/3551]\tStep 2550\tlr 0.00036\tmm 0.996\tLoss 1.4038 \tB_Loss 1.3315 \tV_Loss 0.0072 \t\n",
      "INFO:root:Epoch: [1][2599/3551]\tStep 2600\tlr 0.00037\tmm 0.996\tLoss 1.5849 \tB_Loss 1.5069 \tV_Loss 0.0078 \t\n",
      "INFO:root:Epoch: [1][2649/3551]\tStep 2650\tlr 0.00038\tmm 0.996\tLoss 1.4280 \tB_Loss 1.3538 \tV_Loss 0.0074 \t\n",
      "INFO:root:Epoch: [1][2699/3551]\tStep 2700\tlr 0.00038\tmm 0.996\tLoss 1.3274 \tB_Loss 1.2589 \tV_Loss 0.0069 \t\n",
      "INFO:root:Epoch: [1][2749/3551]\tStep 2750\tlr 0.00039\tmm 0.996\tLoss 1.3095 \tB_Loss 1.2214 \tV_Loss 0.0088 \t\n",
      "INFO:root:Epoch: [1][2799/3551]\tStep 2800\tlr 0.0004\tmm 0.996\tLoss 1.2266 \tB_Loss 1.1070 \tV_Loss 0.0120 \t\n",
      "INFO:root:Epoch: [1][2849/3551]\tStep 2850\tlr 0.00041\tmm 0.996\tLoss 1.1870 \tB_Loss 1.1080 \tV_Loss 0.0079 \t\n",
      "INFO:root:Epoch: [1][2899/3551]\tStep 2900\tlr 0.00041\tmm 0.996\tLoss 1.0538 \tB_Loss 0.9847 \tV_Loss 0.0069 \t\n",
      "INFO:root:Epoch: [1][2949/3551]\tStep 2950\tlr 0.00042\tmm 0.996\tLoss 1.0316 \tB_Loss 0.9664 \tV_Loss 0.0065 \t\n",
      "INFO:root:Epoch: [1][2999/3551]\tStep 3000\tlr 0.00043\tmm 0.996\tLoss 1.0327 \tB_Loss 0.9695 \tV_Loss 0.0063 \t\n",
      "INFO:root:Epoch: [1][3049/3551]\tStep 3050\tlr 0.00043\tmm 0.996\tLoss 1.0294 \tB_Loss 0.9814 \tV_Loss 0.0048 \t\n",
      "INFO:root:Epoch: [1][3099/3551]\tStep 3100\tlr 0.00044\tmm 0.996\tLoss 0.8579 \tB_Loss 0.8223 \tV_Loss 0.0036 \t\n",
      "INFO:root:Epoch: [1][3149/3551]\tStep 3150\tlr 0.00045\tmm 0.996\tLoss 0.9635 \tB_Loss 0.9342 \tV_Loss 0.0029 \t\n",
      "INFO:root:Epoch: [1][3199/3551]\tStep 3200\tlr 0.00045\tmm 0.996\tLoss 0.7977 \tB_Loss 0.7684 \tV_Loss 0.0029 \t\n",
      "INFO:root:Epoch: [1][3249/3551]\tStep 3250\tlr 0.00046\tmm 0.996\tLoss 0.7342 \tB_Loss 0.7092 \tV_Loss 0.0025 \t\n",
      "INFO:root:Epoch: [1][3299/3551]\tStep 3300\tlr 0.00047\tmm 0.996\tLoss 0.6011 \tB_Loss 0.5747 \tV_Loss 0.0026 \t\n",
      "INFO:root:Epoch: [1][3349/3551]\tStep 3350\tlr 0.00048\tmm 0.996\tLoss 0.6414 \tB_Loss 0.6216 \tV_Loss 0.0020 \t\n",
      "INFO:root:Epoch: [1][3399/3551]\tStep 3400\tlr 0.00048\tmm 0.996\tLoss 0.7145 \tB_Loss 0.6813 \tV_Loss 0.0033 \t\n",
      "INFO:root:Epoch: [1][3449/3551]\tStep 3450\tlr 0.00049\tmm 0.996\tLoss 0.6015 \tB_Loss 0.5803 \tV_Loss 0.0021 \t\n",
      "INFO:root:Epoch: [1][3499/3551]\tStep 3500\tlr 0.0005\tmm 0.996\tLoss 0.5361 \tB_Loss 0.5184 \tV_Loss 0.0018 \t\n",
      "INFO:root:Epoch: [1][3549/3551]\tStep 3550\tlr 0.0005\tmm 0.996\tLoss 0.7001 \tB_Loss 0.6798 \tV_Loss 0.0020 \t\n",
      "INFO:root:Epoch 1 training time: 114.37 minutes\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Trainer' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     run_task(config)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     config \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(f)\n\u001b[1;32m      6\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_pct\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m    \n\u001b[0;32m----> 7\u001b[0m \u001b[43mrun_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m, in \u001b[0;36mrun_task\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, trainer\u001b[38;5;241m.\u001b[39mtotal_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      6\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtrain_epoch(epoch)\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 92\u001b[0m, in \u001b[0;36mTrainer.save_checkpoint\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     85\u001b[0m     model_state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m     86\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch,\n\u001b[1;32m     87\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     91\u001b[0m              }\n\u001b[0;32m---> 92\u001b[0m     online_state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monline\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39monline_network\u001b[38;5;241m.\u001b[39mstate_dict()}\n\u001b[1;32m     93\u001b[0m     SAVE_PATH1 \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mckpt_path\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m     SAVE_PATH2 \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mckpt_path\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Trainer' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load configuration\n",
    "    config_file = \"config1.yaml\"\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    config['data_pct'] = 100    \n",
    "    run_task(config)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830cfa4b-be3e-4bd3-9663-b8fe3180cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_start_time = time.time()\n",
    "# roc_auc_scores = []\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     combined_model.train()\n",
    "#     epoch_loss = 0\n",
    "#     for batch in tqdm(train_loader):\n",
    "#         input_ids = batch['caption_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         images = batch['imgs']\n",
    "#         view_1, view_2 = images\n",
    "#         view_1 = view_1.to(device)\n",
    "#         view_2 = view_2.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Ensure you are correctly unpacking the outputs from the combined_model forward pass\n",
    "#         online_1, target_1, text_features_1 = combined_model(view_1, input_ids, attention_mask)\n",
    "#         online_2, target_2, text_features_2 = combined_model(view_2, input_ids, attention_mask)\n",
    "\n",
    "#         # Calculate BYOL losses\n",
    "#         loss_byol = (negative_cosine_similarity(online_1, target_2) + negative_cosine_similarity(online_2, target_1)) / 2\n",
    "\n",
    "        # Calculate VICReg variance losses\n",
    "#         variance_I = vicreg_loss(online_1, online_2)\n",
    "#         variance_T = vicreg_loss(text_features_1, text_features_2)\n",
    "#         loss_vicreg = F.mse_loss(variance_I, variance_T)\n",
    "\n",
    "#         # Combined loss\n",
    "#         loss = (loss_byol + loss_vicreg) / 2\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         epoch_loss += loss.item()\n",
    "\n",
    "#     logging.info(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# total_end_time = time.time()\n",
    "# total_training_time = total_end_time - total_start_time\n",
    "# logging.info(f\"Total training time: {total_training_time:.2f seconds}\")\n",
    "\n",
    "# # Save the model checkpoint\n",
    "# torch.save(combined_model.state_dict(), \"combined_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68714def-12a1-48cb-bcbc-170052da5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training loop for the combined model\n",
    "# total_start_time = time.time()\n",
    "# roc_auc_scores = []\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     combined_model.train()\n",
    "#     epoch_loss = 0\n",
    "#     for batch in tqdm(train_loader):\n",
    "#         input_ids = batch['caption_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         images = batch['imgs']\n",
    "#         view_1, view_2 = images\n",
    "#         view_1 = view_1.to(device)\n",
    "#         view_2 = view_2.to(device)\n",
    "        \n",
    "#         labels = batch['labels'].to(device).float().unsqueeze(1)  # Adjust label shape\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Forward pass for view_1\n",
    "#         outputs_1, online_1, target_1, text_features_1 = combined_model(view_1, input_ids, attention_mask)\n",
    "        \n",
    "#         # Forward pass for view_2 (assuming you need both views for BYOL and VICReg)\n",
    "#         outputs_2, online_2, target_2, text_features_2 = combined_model(view_2, input_ids, attention_mask)\n",
    "\n",
    "#         # Calculate classification loss\n",
    "#         classification_loss = classification_criterion(outputs_1, labels)\n",
    "\n",
    "#         # Calculate BYOL losses (assuming negative_cosine_similarity is defined)\n",
    "#         loss_byol = (negative_cosine_similarity(online_1, target_2) + negative_cosine_similarity(online_2, target_1)) / 2\n",
    "\n",
    "#         # Calculate VICReg variance losses (assuming vicreg_loss is defined)\n",
    "#         variance_I = vicreg_loss(online_1, online_2)\n",
    "#         variance_T = vicreg_loss(text_features_1, text_features_2)\n",
    "#         loss_vicreg = F.mse_loss(variance_I, variance_T)\n",
    "\n",
    "#         # Combined loss\n",
    "#         loss = (classification_loss + loss_byol + loss_vicreg) / 3\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         epoch_loss += loss.item()\n",
    "\n",
    "#     logging.info(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# # Validation loop\n",
    "# combined_model.eval()\n",
    "# val_loss = 0\n",
    "# val_labels = []\n",
    "# val_outputs = []\n",
    "# with torch.no_grad():\n",
    "#     for batch in tqdm(valid_loader):\n",
    "#         input_ids = batch['caption_ids']\n",
    "#         attention_mask = batch['attention_mask']\n",
    "#         images = batch['imgs']\n",
    "#         labels = batch['labels']\n",
    "\n",
    "#         view_1, view_2 = images\n",
    "#         view_1 = view_1.to(device)\n",
    "#         view_2 = view_2.to(device)\n",
    "#         input_ids = input_ids.to(device)\n",
    "#         attention_mask = attention_mask.to(device)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         q_1, t_1, text_features_1 = combined_model(view_1, input_ids, attention_mask)\n",
    "#         q_2, t_2, text_features_2 = combined_model(view_2, input_ids, attention_mask)\n",
    "\n",
    "#         # Calculate classification loss\n",
    "#         outputs_1, _, _ = combined_model(view_1, input_ids, attention_mask)\n",
    "#         classification_loss_1 = classification_criterion(outputs_1, labels)\n",
    "\n",
    "#         outputs_2, _, _ = combined_model(view_2, input_ids, attention_mask)\n",
    "#         classification_loss_2 = classification_criterion(outputs_2, labels)\n",
    "\n",
    "#         classification_loss = (classification_loss_1 + classification_loss_2) / 2\n",
    "\n",
    "#         # Calculate BYOL losses\n",
    "#         loss_byol = (negative_cosine_similarity(q_1, t_2) + negative_cosine_similarity(q_2, t_1)) / 2\n",
    "\n",
    "#         # Calculate VICReg variance losses\n",
    "#         variance_I = vicreg_loss(q_1, q_2)\n",
    "#         variance_T = vicreg_loss(text_features_1, text_features_2)\n",
    "#         loss_vicreg = F.mse_loss(variance_I, variance_T)\n",
    "\n",
    "#         # Combined loss\n",
    "#         loss = (classification_loss + loss_byol + loss_vicreg) / 3\n",
    "\n",
    "#         val_loss += loss.item()\n",
    "#         val_labels.append(labels.cpu().numpy())\n",
    "#         val_outputs.append(outputs_1.cpu().numpy())  # Use outputs from the first view for ROC AUC calculation\n",
    "\n",
    "# # Calculate ROC AUC score\n",
    "# val_labels = np.concatenate(val_labels)\n",
    "# val_outputs = np.concatenate(val_outputs)\n",
    "# roc_auc = roc_auc_score(val_labels, val_outputs)\n",
    "# roc_auc_scores.append(roc_auc)\n",
    "\n",
    "# logging.info(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss/len(valid_loader):.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "# print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss/len(valid_loader):.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# total_end_time = time.time()\n",
    "# total_training_time = total_end_time - total_start_time\n",
    "# logging.info(f\"Total training time: {total_training_time:.2f} seconds\")\n",
    "\n",
    "# # Save the model checkpoint\n",
    "# torch.save(combined_model.state_dict(), \"combined_model.pth\")\n",
    "\n",
    "# # Plot the ROC AUC scores over epochs\n",
    "# plt.figure()\n",
    "# plt.plot(range(1, num_epochs+1), roc_auc_scores, marker='o')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('ROC AUC Score')\n",
    "# plt.title('ROC AUC Score over Epochs')\n",
    "# plt.savefig('roc_auc_scores.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ec362f-89b1-4932-9ce4-853f53cae48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(batch.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d857dec6-48b6-44ec-be10-07fdacaddb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
